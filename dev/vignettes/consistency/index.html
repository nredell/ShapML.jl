<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Stochastic vs. TreeSHAP · ShapML</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ShapML logo"/></a><div class="docs-package-name"><span class="docs-autofit">ShapML</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><span class="tocitem">Vignettes</span><ul><li class="is-active"><a class="tocitem" href>Stochastic vs. TreeSHAP</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Setup-1"><span>Setup</span></a></li><li class="toplevel"><a class="tocitem" href="#Comparison-1"><span>Comparison</span></a></li><li><a class="tocitem" href="#Load-Packages-1"><span>Load Packages</span></a></li><li><a class="tocitem" href="#Load-Data-in-R-1"><span>Load Data in R</span></a></li><li><a class="tocitem" href="#Train-ML-Model-in-R-1"><span>Train ML Model in R</span></a></li><li><a class="tocitem" href="#Shapley-Algorithms-1"><span>Shapley Algorithms</span></a></li><li><a class="tocitem" href="#Results-1"><span>Results</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../functions/functions/">Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Vignettes</a></li><li class="is-active"><a href>Stochastic vs. TreeSHAP</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Stochastic vs. TreeSHAP</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/nredell/ShapML.jl/blob/master/docs/src/vignettes/consistency.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Purpose-1"><a class="docs-heading-anchor" href="#Purpose-1">Purpose</a><a class="docs-heading-anchor-permalink" href="#Purpose-1" title="Permalink"></a></h1><ul><li><p>The goal of this vignette is to demonstrate how, for the same   boosted tree prediction model, the stochastic Shapley values from   <code>ShapML</code> correlate with the non-stochastic, tree-based Shapley   values from the Python <strong><a href="https://github.com/slundberg/shap">shap</a></strong>   package using the implementation discussed   <strong><a href="https://arxiv.org/abs/1802.03888">here</a></strong>.</p></li><li><p>While <code>shap</code> provides the preferred Shapley value algorithm when   modeling with boosted trees, this vignette demonstrates that the   sampling-based <code>ShapML</code> implementation returns nearly identical   results while having the ability to work with all classes of ML   models.</p></li></ul><h1 id="Setup-1"><a class="docs-heading-anchor" href="#Setup-1">Setup</a><a class="docs-heading-anchor-permalink" href="#Setup-1" title="Permalink"></a></h1><ul><li><p>Because the tree-based Shapley value algorithm is not currently   available in <code>Julia</code>, we’ll use   <strong><a href="https://catboost.ai/">catboost’s</a></strong> <code>R</code> package which provides a   port of the tree-based algorithm in <code>shap</code> in   <code>catboost.get_feature_importance()</code>.</p></li><li><p>Outline of the comparison:</p><ol><li><code>R</code>: Train the ML model.</li><li><code>R</code>: Calculate the tree-based Shapley values.</li><li><code>R</code>: Write the <code>predict()</code> wrapper that works with the trained  model.</li><li><code>Julia</code>: Using <code>RCall</code>, convert the trained model and  <code>predict()</code> function into <code>Julia</code> objects.</li><li><code>Julia</code>: Calculate the stochastic Shapley values, passing in the  objects from step 4.</li><li><code>R</code>: Compare the results.</li></ol></li></ul><h1 id="Comparison-1"><a class="docs-heading-anchor" href="#Comparison-1">Comparison</a><a class="docs-heading-anchor-permalink" href="#Comparison-1" title="Permalink"></a></h1><h2 id="Load-Packages-1"><a class="docs-heading-anchor" href="#Load-Packages-1">Load Packages</a><a class="docs-heading-anchor-permalink" href="#Load-Packages-1" title="Permalink"></a></h2><h3 id="R-1"><a class="docs-heading-anchor" href="#R-1">R</a><a class="docs-heading-anchor-permalink" href="#R-1" title="Permalink"></a></h3><ul><li>Allow <code>rmarkdown</code> to pass <code>Julia</code> and <code>R</code> objects between code   blocks.</li></ul><pre><code class="language-r">library(JuliaCall)

JuliaCall::julia_setup()

# Setting the Julia path first in the R environment points JuliaCall to the right Julia .dll files.
Sys.setenv(PATH = paste(&quot;C:/Users/nredell/AppData/Local/Julia-1.3.1/bin&quot;, Sys.getenv(&quot;PATH&quot;), sep = &quot;;&quot;))

library(dplyr)
library(tidyr)
library(ggplot2)
library(shapFlex)
library(devtools)

if (!&quot;catboost&quot; %in% installed.packages()[, &quot;Package&quot;]) {
  # Install catboost which is not available on CRAN (Windows link below).
  devtools::install_url(&#39;https://github.com/catboost/catboost/releases/download/v0.20/catboost-R-Windows-0.20.tgz&#39;,
                        INSTALL_opts = c(&quot;--no-multiarch&quot;))
}

library(catboost)  # version 0.20</code></pre><h3 id="Julia-1"><a class="docs-heading-anchor" href="#Julia-1">Julia</a><a class="docs-heading-anchor-permalink" href="#Julia-1" title="Permalink"></a></h3><pre><code class="language-julia">using ShapML
using Random
using DataFrames
using RCall</code></pre><h2 id="Load-Data-in-R-1"><a class="docs-heading-anchor" href="#Load-Data-in-R-1">Load Data in R</a><a class="docs-heading-anchor-permalink" href="#Load-Data-in-R-1" title="Permalink"></a></h2><pre><code class="language-r">data(&quot;data_adult&quot;, package = &quot;shapFlex&quot;)
data &lt;- data_adult

outcome_name &lt;- &quot;income&quot;  # A binary outcome.
outcome_col &lt;- which(names(data) == outcome_name)</code></pre><h2 id="Train-ML-Model-in-R-1"><a class="docs-heading-anchor" href="#Train-ML-Model-in-R-1">Train ML Model in R</a><a class="docs-heading-anchor-permalink" href="#Train-ML-Model-in-R-1" title="Permalink"></a></h2><ul><li>The accuracy of the model isn’t entirely important because we’re   interested in comparing Shapley values across algorithms: stochastic   in <code>Julia</code> vs. tree-based in <code>R</code>.</li></ul><pre><code class="language-r">cat_features &lt;- which(unlist(Map(is.factor, data[, -outcome_col]))) - 1

data_pool &lt;- catboost.load_pool(data = data[, -outcome_col],
                                label = as.vector(as.numeric(data[, outcome_col])) - 1,
                                cat_features = cat_features)

set.seed(224)
model_catboost &lt;- catboost.train(data_pool, NULL,
                                 params = list(loss_function = &#39;CrossEntropy&#39;,
                                               iterations = 30, logging_level = &quot;Silent&quot;))</code></pre><h2 id="Shapley-Algorithms-1"><a class="docs-heading-anchor" href="#Shapley-Algorithms-1">Shapley Algorithms</a><a class="docs-heading-anchor-permalink" href="#Shapley-Algorithms-1" title="Permalink"></a></h2><ul><li>We’ll explain the same 300 instances with each algorithm.</li></ul><h3 id="Tree-based-Shapley-values-in-R-1"><a class="docs-heading-anchor" href="#Tree-based-Shapley-values-in-R-1">Tree-based Shapley values in R</a><a class="docs-heading-anchor-permalink" href="#Tree-based-Shapley-values-in-R-1" title="Permalink"></a></h3><pre><code class="language-r">data_pool &lt;- catboost.load_pool(data = data[1:300, -outcome_col],
                                label = as.vector(as.numeric(data[1:300, outcome_col])) - 1,
                                cat_features = cat_features)

data_shap_tree &lt;- catboost.get_feature_importance(model_catboost, pool = data_pool,
                                                  type = &quot;ShapValues&quot;)

data_shap_tree &lt;- data.frame(data_shap_tree[, -ncol(data_shap_tree)])  # Remove the intercept column.

data_shap_tree$index &lt;- 1:nrow(data_shap_tree)

data_shap_tree &lt;- tidyr::gather(data_shap_tree, key = &quot;feature_name&quot;,
                                value = &quot;shap_effect_catboost&quot;, -index)</code></pre><h3 id="Stochastic-Shapley-values-in-Julia-1"><a class="docs-heading-anchor" href="#Stochastic-Shapley-values-in-Julia-1">Stochastic Shapley values in Julia</a><a class="docs-heading-anchor-permalink" href="#Stochastic-Shapley-values-in-Julia-1" title="Permalink"></a></h3><h4 id="Predict-function-in-R-1"><a class="docs-heading-anchor" href="#Predict-function-in-R-1">Predict function in R</a><a class="docs-heading-anchor-permalink" href="#Predict-function-in-R-1" title="Permalink"></a></h4><ul><li>For <code>ShapML</code>, the required user-defined prediction function takes 2   positional arguments and returns a 1-column <code>DataFrame</code> of model   predictions.</li></ul><pre><code class="language-r">predict_function &lt;- function(model, data) {

  data_pool &lt;- catboost.load_pool(data = data, cat_features = cat_features)

  # Predictions and Shapley explanations will be in log-odds space.
  data_pred &lt;- data.frame(&quot;y_pred&quot; = catboost.predict(model, data_pool))

  return(data_pred)
}</code></pre><ul><li>In <code>Julia</code>, convert the input data, the trained model, and the   <code>predict()</code> function into <code>Julia</code> objects.</li></ul><pre><code class="language-julia">data = RCall.reval(&quot;data&quot;)
data = convert(DataFrame, data)

outcome_name = RCall.reval(&quot;outcome_name&quot;)
outcome_name = convert(String, outcome_name)

model_catboost = RCall.reval(&quot;model_catboost&quot;)

predict_function = RCall.reval(&quot;predict_function&quot;)
predict_function = convert(Function, predict_function)</code></pre><h4 id="ShapML.shap-1"><a class="docs-heading-anchor" href="#ShapML.shap-1">ShapML.shap</a><a class="docs-heading-anchor-permalink" href="#ShapML.shap-1" title="Permalink"></a></h4><pre><code class="language-julia">explain = copy(data[1:300, :])  # Compute Shapley feature-level predictions for all instances.
explain = select(explain, Not(Symbol(outcome_name)))  # Remove the outcome column.

reference = copy(data)  # An optional dataset for computing the intercept/baseline prediction.
reference = select(reference, Not(Symbol(outcome_name)))  # Remove the outcome column.

Random.seed!(224)
data_shap = ShapML.shap(explain = explain,
                        reference = reference,
                        model = model_catboost,
                        predict_function = predict_function,
                        sample_size = 100  # Number of Monte Carlo samples.
                        )</code></pre><h2 id="Results-1"><a class="docs-heading-anchor" href="#Results-1">Results</a><a class="docs-heading-anchor-permalink" href="#Results-1" title="Permalink"></a></h2><ul><li>For <strong>10 out of 13 model features</strong>, the <strong>correlation</strong> between the   stochastic and tree-based Shapley values was <strong>&gt;= .99</strong> and above   .92 for the remaining features.</li></ul><pre><code class="language-r">data_shap &lt;- JuliaCall::julia_eval(&quot;data_shap&quot;)  # Pass from Julia to R.
data_shap$feature_value &lt;- NULL</code></pre><pre><code class="language-r">data_all &lt;- dplyr::inner_join(data_shap, data_shap_tree, by = c(&quot;index&quot;, &quot;feature_name&quot;))</code></pre><pre><code class="language-r">data_cor &lt;- data_all %&gt;%
  dplyr::group_by(feature_name) %&gt;%
  dplyr::summarise(&quot;cor_coef&quot; = round(cor(shap_effect, shap_effect_catboost), 3))

data_cor</code></pre><pre><code class="language-none">## # A tibble: 13 x 2
##    feature_name   cor_coef
##    &lt;chr&gt;             &lt;dbl&gt;
##  1 age               0.994
##  2 capital_gain      0.997
##  3 capital_loss      0.983
##  4 education         0.991
##  5 education_num     0.998
##  6 hours_per_week    0.993
##  7 marital_status    0.99
##  8 native_country    0.99
##  9 occupation        0.996
## 10 race              0.998
## 11 relationship      0.991
## 12 sex               0.924
## 13 workclass         0.975</code></pre><pre><code class="language-r">p &lt;- ggplot(data_all, aes(shap_effect_catboost, shap_effect))
p &lt;- p + geom_point(alpha = .25)
p &lt;- p + geom_abline(color = &quot;red&quot;)
p &lt;- p + facet_wrap(~ feature_name, scales = &quot;free&quot;)
p &lt;- p + theme_bw() + xlab(&quot;catboost tree-based Shapley values&quot;) + ylab(&quot;ShapML stochastic Shapley values&quot;) +
  theme(axis.title = element_text(face = &quot;bold&quot;))
p</code></pre><p><img src="../shap_cor_plot.png" alt/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Introduction</a><a class="docs-footer-nextpage" href="../../functions/functions/">Functions »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 23 February 2020 03:15">Sunday 23 February 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
